---
layout: post
title:  "How Skynet will actually happen"
date:  2015-08-04
author: Andrew Stroup
permalink: blog/how-skynet-will-actually-happen
img: images/posts/skynet.jpg
---
<img src="{{ baseurl }}/images/posts/skyney.jpg" class="img-responsive">

Back in December, I was on a phone interview for an article with The Daily Dot called [Stephen Hawking thinks artificial intelligence will destroy us](http://www.dailydot.com/technology/stephen-hawking-artificial-intelligence-civilization/), where they asked my opinion on if I thought artificial intelligence would destroy humanity if left uncheck. The interview came about because of my involvement with co-founding [MegaBots, Inc.](http://megabots.com), a robotics startup focused on building a new sports league of giant fighting robots.

In the article I side with Hawking's opinion (who am I to argue with the smartest person on the planet?), but caveated that "it really comes down to how companies and people utilize the technology that will dictate its future". The article covers various roboticist's opinions on the topic, covering the spectrum of academia and private sector opinions.

Lately I've spent some time thinking about this topic again, which was sparked from a conversation I had with a friend at the [MIT Media Lab](https://www.media.mit.edu/) [Center for Bits and Atoms](http://cba.mit.edu/), Matt Carney, who prior to starting his PhD program, worked at notable places like [IDEO](http://www.ideo.com) and [Meka Robotics](https://en.wikipedia.org/wiki/Meka_Robotics) (acquired by Google) as a mechanical engineer.

While throwing back a couple of tasty beverages at the Muddy Charles Pub (the iconic MIT grad school bar), we were chatting about robotics as all good nerds should and ended up discussing our opinions of next steps in robotic technology. Referencing a previous conversation Matt had with Gill Pratt, [DARPA Program Manager](http://www.darpa.mil/staff/dr-gill-a-pratt) who oversaw the [DARPA Robotics Challenge](https://en.wikipedia.org/wiki/DARPA_Robotics_Challenge), about leveraging the cloud for a robotic's operating system.

First off, if you haven't heard of the cloud: 1) why are you reading this article and how did you end up on my blog and 2) start with this [Gizmodo article](http://gizmodo.com/what-is-the-cloud-and-where-is-it-1682276210). 

The concept is around robots sharing common computing power required to perform higher level functions. If those higher level functions, which often require a signficant amount of computational resources, could be shared via the cloud, the speed of robotic advances could drastically increase, which is supported by the idealogy of open source code (e.g. [ROS - Robotic Operating System](http://www.ros.org/)).

I know, I know, you must be asking yourself by now, when is this guy going to get to the good stuff - where we all die by the robots we create? Well that's just it, this is where it'd happen. As the unified approach to robotic development via open source collaboration and utilization of the cloud as an operating system converges, an increase in the impelmentation of 'artificial intelligence' code like machine learning would likely be incorporated to support robots perfoming even higher level functions. At this point, we're talking about robots across the globe that share a singular 'awareness' that's constantly adapting ... YUP!

Let's break down why this would potentially put humanity at risk. If you were engaged with Robot A in the United States that shared the 'cloud intelligence' with thousands of robots across the globe and Robot B in China who was engaged in the same activity experienced something that forced the shared algorithms to re-process the engagement in a different approach, Robot A would instantaneously change its interactions with you based on zero influence with the physical world, but instead update due to its connectivity to said 'cloud intelligence.'

Scary, right?

It's like the idea that you could have infinite access to data instantenously and were constantly improving and iterating on this information irregardless of your interaction with the physical world, something we're very much not accustomed to and airs on the side of eery.

This is where Skynet comes in. It wouldn't take much to create the tipping point where the machine learning algorithms would be presented with a scenario where humans would be identified as an unnecessary element in tasks, engagement, or utility, which could potentially lead to the scary post-apocalyptic universe that we've been treated to on the silver screen.

Should you be scared? Probably, but just like any world social issue, it takes education, awareness, and action to clearly draw the lines of what's acceptable or not; and in this case, includes an extra layer of complexity with the balance of throttling or focusing technological advancement. At least be comforted by the fact smart minds like Elon Musk and Stephen Hawking are vocally against the use of [Artificial Intelligence weapons](http://time.com/3973500/elon-musk-stephen-hawking-ai-weapons/), hopefully a step in the right direction. 